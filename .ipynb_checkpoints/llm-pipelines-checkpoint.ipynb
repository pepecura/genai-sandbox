{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# @title Copyright & License (click to expand)\n",
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsv4jGuU89rX"
   },
   "source": [
    "# Vertex AI Pipelines and Evaluation of LLMs\n",
    "Auto side-by-side evaluation: </br>\n",
    "https://cloud.google.com/vertex-ai/generative-ai/docs/models/side-by-side-eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "overview:automl"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This tutorial demonstrates how to use the Vertex AI Pipelines for LLM Evaluation in a Question and Answer use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip:mbsdk"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.44.0-py2.py3-none-any.whl.metadata (27 kB)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.16.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting kfp\n",
      "  Downloading kfp-2.7.0.tar.gz (441 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.8/441.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting google-cloud-pipeline-components\n",
      "  Downloading google_cloud_pipeline_components-2.11.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading google_api_core-2.18.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-auth<3.0.0dev,>=2.14.1 (from google-cloud-aiplatform)\n",
      "  Downloading google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.0 (from google-cloud-aiplatform)\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 (from google-cloud-aiplatform)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting packaging>=14.3 (from google-cloud-aiplatform)\n",
      "  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting google-cloud-bigquery<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform)\n",
      "  Using cached google_cloud_bigquery-3.19.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform)\n",
      "  Downloading shapely-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage)\n",
      "  Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.6.0 (from google-cloud-storage)\n",
      "  Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting requests<3.0.0dev,>=2.18.0 (from google-cloud-storage)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage)\n",
      "  Downloading google_crc32c-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting click<9,>=8.0.0 (from kfp)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting docstring-parser<1,>=0.7.3 (from kfp)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting kfp-pipeline-spec==0.3.0 (from kfp)\n",
      "  Downloading kfp_pipeline_spec-0.3.0-py3-none-any.whl.metadata (329 bytes)\n",
      "Collecting kfp-server-api<2.1.0,>=2.0.0 (from kfp)\n",
      "  Downloading kfp-server-api-2.0.5.tar.gz (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kubernetes<27,>=8.0.0 (from kfp)\n",
      "  Downloading kubernetes-26.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting PyYAML<7,>=5.3 (from kfp)\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting requests-toolbelt<1,>=0.8.0 (from kfp)\n",
      "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tabulate<1,>=0.8.6 (from kfp)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting urllib3<2.0.0 (from kfp)\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Jinja2<4,>=3.1.2 (from google-cloud-pipeline-components)\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading grpcio_status-1.62.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting python-dateutil<3.0dev,>=2.7.2 (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform)\n",
      "  Downloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2<4,>=3.1.2->google-cloud-pipeline-components)\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting six>=1.10 (from kfp-server-api<2.1.0,>=2.0.0->kfp)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting certifi (from kfp-server-api<2.1.0,>=2.0.0->kfp)\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting setuptools>=21.0.0 (from kubernetes<27,>=8.0.0->kfp)\n",
      "  Downloading setuptools-69.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes<27,>=8.0.0->kfp)\n",
      "  Downloading websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting requests-oauthlib (from kubernetes<27,>=8.0.0->kfp)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0dev,>=2.18.0->google-cloud-storage)\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0dev,>=2.18.0->google-cloud-storage)\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting numpy<2,>=1.14 (from shapely<3.0.0dev->google-cloud-aiplatform)\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes<27,>=8.0.0->kfp)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading google_cloud_aiplatform-1.44.0-py2.py3-none-any.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.16.0-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.6/125.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kfp_pipeline_spec-0.3.0-py3-none-any.whl (12 kB)\n",
      "Downloading google_cloud_pipeline_components-2.11.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached google_cloud_bigquery-3.19.0-py2.py3-none-any.whl (232 kB)\n",
      "Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl (333 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.7/333.7 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_crc32c-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Downloading google_resumable_media-2.7.0-py2.py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-26.1.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.0-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.1/142.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl (25 kB)\n",
      "Downloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading grpcio_status-1.62.1-py3-none-any.whl (14 kB)\n",
      "Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading setuptools-69.2.0-py3-none-any.whl (821 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.5/821.5 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: kfp, kfp-server-api\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-2.7.0-py3-none-any.whl size=610418 sha256=0e371c47ab3a9fac3aeca91d398899cfdffd6fb9c936201ce1f7bd232c363234\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/9e/7d/a4/f9d013e82681c9746ef10de3b00456163577a99279c5ed673d\n",
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp-server-api: filename=kfp_server_api-2.0.5-py3-none-any.whl size=114732 sha256=ad32df67b210f612aa9d8dea4a609e2cf47683f828fa9f7aabbd812da128a9c6\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/ac/4f/f0/2f622aadcbf8921fb72d24f52efaffacc235f863c195c289c5\n",
      "Successfully built kfp kfp-server-api\n",
      "Installing collected packages: websocket-client, urllib3, tabulate, six, setuptools, PyYAML, pyasn1, protobuf, packaging, oauthlib, numpy, MarkupSafe, idna, grpcio, google-crc32c, docstring-parser, click, charset-normalizer, certifi, cachetools, shapely, rsa, requests, python-dateutil, pyasn1-modules, proto-plus, kfp-pipeline-spec, Jinja2, googleapis-common-protos, google-resumable-media, requests-toolbelt, requests-oauthlib, kfp-server-api, grpcio-status, google-auth, kubernetes, grpc-google-iam-v1, google-api-core, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, kfp, google-cloud-aiplatform, google-cloud-pipeline-components\n",
      "  Attempting uninstall: websocket-client\n",
      "    Found existing installation: websocket-client 1.7.0\n",
      "    Uninstalling websocket-client-1.7.0:\n",
      "      Successfully uninstalled websocket-client-1.7.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.18\n",
      "    Uninstalling urllib3-1.26.18:\n",
      "      Successfully uninstalled urllib3-1.26.18\n",
      "  Attempting uninstall: tabulate\n",
      "    Found existing installation: tabulate 0.9.0\n",
      "    Uninstalling tabulate-0.9.0:\n",
      "      Successfully uninstalled tabulate-0.9.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 69.0.3\n",
      "    Uninstalling setuptools-69.0.3:\n",
      "      Successfully uninstalled setuptools-69.0.3\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Successfully uninstalled PyYAML-6.0.1\n",
      "  Attempting uninstall: pyasn1\n",
      "    Found existing installation: pyasn1 0.5.1\n",
      "    Uninstalling pyasn1-0.5.1:\n",
      "      Successfully uninstalled pyasn1-0.5.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.2\n",
      "    Uninstalling packaging-23.2:\n",
      "      Successfully uninstalled packaging-23.2\n",
      "  Attempting uninstall: oauthlib\n",
      "    Found existing installation: oauthlib 3.2.2\n",
      "    Uninstalling oauthlib-3.2.2:\n",
      "      Successfully uninstalled oauthlib-3.2.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/envs/pytorch/lib/python3.10/site-packages/~umpy'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.3\n",
      "    Uninstalling MarkupSafe-2.1.3:\n",
      "      Successfully uninstalled MarkupSafe-2.1.3\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.6\n",
      "    Uninstalling idna-3.6:\n",
      "      Successfully uninstalled idna-3.6\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.60.0\n",
      "    Uninstalling grpcio-1.60.0:\n",
      "      Successfully uninstalled grpcio-1.60.0\n",
      "  Attempting uninstall: google-crc32c\n",
      "    Found existing installation: google-crc32c 1.5.0\n",
      "    Uninstalling google-crc32c-1.5.0:\n",
      "      Successfully uninstalled google-crc32c-1.5.0\n",
      "  Attempting uninstall: docstring-parser\n",
      "    Found existing installation: docstring-parser 0.15\n",
      "    Uninstalling docstring-parser-0.15:\n",
      "      Successfully uninstalled docstring-parser-0.15\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Successfully uninstalled click-8.1.7\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.3.2\n",
      "    Uninstalling charset-normalizer-3.3.2:\n",
      "      Successfully uninstalled charset-normalizer-3.3.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2023.11.17\n",
      "    Uninstalling certifi-2023.11.17:\n",
      "      Successfully uninstalled certifi-2023.11.17\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 4.2.4\n",
      "    Uninstalling cachetools-4.2.4:\n",
      "      Successfully uninstalled cachetools-4.2.4\n",
      "  Attempting uninstall: shapely\n",
      "    Found existing installation: shapely 2.0.2\n",
      "    Uninstalling shapely-2.0.2:\n",
      "      Successfully uninstalled shapely-2.0.2\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.9\n",
      "    Uninstalling rsa-4.9:\n",
      "      Successfully uninstalled rsa-4.9\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: pyasn1-modules\n",
      "    Found existing installation: pyasn1-modules 0.3.0\n",
      "    Uninstalling pyasn1-modules-0.3.0:\n",
      "      Successfully uninstalled pyasn1-modules-0.3.0\n",
      "  Attempting uninstall: proto-plus\n",
      "    Found existing installation: proto-plus 1.23.0\n",
      "    Uninstalling proto-plus-1.23.0:\n",
      "      Successfully uninstalled proto-plus-1.23.0\n",
      "  Attempting uninstall: kfp-pipeline-spec\n",
      "    Found existing installation: kfp-pipeline-spec 0.2.2\n",
      "    Uninstalling kfp-pipeline-spec-0.2.2:\n",
      "      Successfully uninstalled kfp-pipeline-spec-0.2.2\n",
      "  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 3.1.3\n",
      "    Uninstalling Jinja2-3.1.3:\n",
      "      Successfully uninstalled Jinja2-3.1.3\n",
      "  Attempting uninstall: googleapis-common-protos\n",
      "    Found existing installation: googleapis-common-protos 1.62.0\n",
      "    Uninstalling googleapis-common-protos-1.62.0:\n",
      "      Successfully uninstalled googleapis-common-protos-1.62.0\n",
      "  Attempting uninstall: google-resumable-media\n",
      "    Found existing installation: google-resumable-media 2.7.0\n",
      "    Uninstalling google-resumable-media-2.7.0:\n",
      "      Successfully uninstalled google-resumable-media-2.7.0\n",
      "  Attempting uninstall: requests-toolbelt\n",
      "    Found existing installation: requests-toolbelt 0.10.1\n",
      "    Uninstalling requests-toolbelt-0.10.1:\n",
      "      Successfully uninstalled requests-toolbelt-0.10.1\n",
      "  Attempting uninstall: requests-oauthlib\n",
      "    Found existing installation: requests-oauthlib 1.3.1\n",
      "    Uninstalling requests-oauthlib-1.3.1:\n",
      "      Successfully uninstalled requests-oauthlib-1.3.1\n",
      "  Attempting uninstall: kfp-server-api\n",
      "    Found existing installation: kfp-server-api 2.0.5\n",
      "    Uninstalling kfp-server-api-2.0.5:\n",
      "      Successfully uninstalled kfp-server-api-2.0.5\n",
      "  Attempting uninstall: grpcio-status\n",
      "    Found existing installation: grpcio-status 1.48.2\n",
      "    Uninstalling grpcio-status-1.48.2:\n",
      "      Successfully uninstalled grpcio-status-1.48.2\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.28.1\n",
      "    Uninstalling google-auth-2.28.1:\n",
      "      Successfully uninstalled google-auth-2.28.1\n",
      "  Attempting uninstall: kubernetes\n",
      "    Found existing installation: kubernetes 26.1.0\n",
      "    Uninstalling kubernetes-26.1.0:\n",
      "      Successfully uninstalled kubernetes-26.1.0\n",
      "  Attempting uninstall: grpc-google-iam-v1\n",
      "    Found existing installation: grpc-google-iam-v1 0.13.0\n",
      "    Uninstalling grpc-google-iam-v1-0.13.0:\n",
      "      Successfully uninstalled grpc-google-iam-v1-0.13.0\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 2.17.1\n",
      "    Uninstalling google-api-core-2.17.1:\n",
      "      Successfully uninstalled google-api-core-2.17.1\n",
      "  Attempting uninstall: google-cloud-core\n",
      "    Found existing installation: google-cloud-core 2.4.1\n",
      "    Uninstalling google-cloud-core-2.4.1:\n",
      "      Successfully uninstalled google-cloud-core-2.4.1\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.15.0\n",
      "    Uninstalling google-cloud-storage-2.15.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.15.0\n",
      "  Attempting uninstall: google-cloud-resource-manager\n",
      "    Found existing installation: google-cloud-resource-manager 1.11.0\n",
      "    Uninstalling google-cloud-resource-manager-1.11.0:\n",
      "      Successfully uninstalled google-cloud-resource-manager-1.11.0\n",
      "  Attempting uninstall: google-cloud-bigquery\n",
      "    Found existing installation: google-cloud-bigquery 3.19.0\n",
      "    Uninstalling google-cloud-bigquery-3.19.0:\n",
      "      Successfully uninstalled google-cloud-bigquery-3.19.0\n",
      "  Attempting uninstall: kfp\n",
      "    Found existing installation: kfp 2.5.0\n",
      "    Uninstalling kfp-2.5.0:\n",
      "      Successfully uninstalled kfp-2.5.0\n",
      "  Attempting uninstall: google-cloud-aiplatform\n",
      "    Found existing installation: google-cloud-aiplatform 1.43.0\n",
      "    Uninstalling google-cloud-aiplatform-1.43.0:\n",
      "      Successfully uninstalled google-cloud-aiplatform-1.43.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.0.323 requires dataclasses-json<0.7,>=0.5.7, which is not installed.\n",
      "google-cloud-translate 2.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.15.0, but you have google-api-core 2.18.0 which is incompatible.\n",
      "google-cloud-translate 2.0.1 requires google-cloud-core<2.0dev,>=1.1.0, but you have google-cloud-core 2.4.1 which is incompatible.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.18.0 which is incompatible.\n",
      "google-cloud-datastore 1.15.5 requires protobuf<4.0.0dev, but you have protobuf 4.25.3 which is incompatible.\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Jinja2-3.1.3 MarkupSafe-2.1.5 PyYAML-6.0.1 cachetools-5.3.2 certifi-2024.2.2 charset-normalizer-3.3.2 click-8.1.7 docstring-parser-0.16 google-api-core-1.34.0 google-auth-2.26.2 google-cloud-aiplatform-1.39.0 google-cloud-bigquery-3.15.0 google-cloud-core-2.4.1 google-cloud-pipeline-components-2.11.0 google-cloud-resource-manager-1.12.3 google-cloud-storage-2.14.0 google-crc32c-1.5.0 google-resumable-media-2.7.0 googleapis-common-protos-1.63.0 grpc-google-iam-v1-0.13.0 grpcio-1.62.1 grpcio-status-1.62.1 idna-3.6 kfp-2.7.0 kfp-pipeline-spec-0.3.0 kfp-server-api-2.0.5 kubernetes-26.1.0 numpy-1.26.4 oauthlib-3.2.2 packaging-24.0 proto-plus-1.23.0 protobuf-4.25.3 pyasn1-0.5.1 pyasn1-modules-0.3.0 python-dateutil-2.9.0.post0 requests-2.31.0 requests-oauthlib-2.0.0 requests-toolbelt-0.10.1 rsa-4.9 setuptools-69.2.0 shapely-2.0.3 six-1.16.0 tabulate-0.9.0 urllib3-1.26.18 websocket-client-1.7.0\n"
     ]
    }
   ],
   "source": [
    "! pip3 install --upgrade --force-reinstall google-cloud-aiplatform \\\n",
    "                         google-cloud-storage \\\n",
    "                         kfp \\\n",
    "                         google-cloud-pipeline-components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GPgNN7eeX1l"
   },
   "source": [
    "Check the package versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NN0mULkEeb84",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 2.7.0\n",
      "google-cloud-aiplatform==1.39.0\n",
      "google-cloud-pipeline-components==2.11.0\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! pip3 freeze | grep aiplatform\n",
    "! pip3 freeze | grep components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Before you begin Restart Kernel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "set_project_id",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT[0]\n",
    "\n",
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### Region\n",
    "\n",
    "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2dw8q9fdQEH5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:mbsdk"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "Create a storage bucket to store intermediate artifacts such as datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bucket",
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://{PROJECT_ID}-llmops\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://tadelle-372416-llmops'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "autoset_bucket"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "id": "91c46850b49b",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://tadelle-372416-llmops/...\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85c4ecfd133a"
   },
   "source": [
    "#### Service Account \n",
    "\n",
    "You use a service account to create Vertex AI Pipeline jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_vars"
   },
   "source": [
    "### Import libraries and define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "V0aexAES_cnZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import compiler, dsl\n",
    "from kfp.dsl import component, Input, Output, Artifact, InputPath, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk"
   },
   "source": [
    "## Initialize Vertex AI SDK for Python\n",
    "\n",
    "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = \"genai-llm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "init_aip:mbsdk",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Tensorboard\n",
      "Create Tensorboard backing LRO: projects/81492352225/locations/us-central1/tensorboards/2043759019570495488/operations/4585743075929751552\n",
      "Tensorboard created. Resource name: projects/81492352225/locations/us-central1/tensorboards/2043759019570495488\n",
      "To use this Tensorboard in another session:\n",
      "tb = aiplatform.Tensorboard('projects/81492352225/locations/us-central1/tensorboards/2043759019570495488')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-c06db72b-8159-485c-8a32-d1607258bbd8\" href=\"#view-view-vertex-resource-c06db72b-8159-485c-8a32-d1607258bbd8\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-c06db72b-8159-485c-8a32-d1607258bbd8');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/genai-llm/runs?project=tadelle-372416');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/genai-llm/runs?project=tadelle-372416', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID, \n",
    "    staging_bucket=BUCKET_URI,\n",
    "    location=REGION,\n",
    "    experiment=experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# aiplatform.start_run(run=\"gemini-textbison-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"langchain\", \"langchain-google-vertexai\", \"pandas\"],\n",
    "    base_image=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-12.py310:latest\" #TODO Find Relevant Base Image!!!,\n",
    ")\n",
    "def prompt_vertex_llm_apis(\n",
    "    project_id: str,\n",
    "    region_id: str,\n",
    "    prompt_file: str,\n",
    "    prompt_template: str,\n",
    "    prompt_variables: List,\n",
    "    model_name: str,\n",
    "    model_endpoint: Input[Artifact],\n",
    "    model_response: Output[Dataset]\n",
    "):\n",
    "    \n",
    "    from langchain_google_vertexai import VertexAI\n",
    "    from langchain_core.prompts import PromptTemplate\n",
    "    import pandas as pd\n",
    "\n",
    "    model_endpoint = model_endpoint.path\n",
    "    \n",
    "    prompt_df = pd.read_csv(prompt_file)\n",
    "    for index, row in prompt_df.iterrows():\n",
    "    \n",
    "        print(row[\"id\"], row[\"question\"], row[\"context\"])\n",
    "    \n",
    "        prompt = PromptTemplate(input_variables=prompt_variables, template=prompt_template) \n",
    "        prompt_formatted_str: str = prompt.format(\n",
    "            question=row[\"question\"],\n",
    "            context=row[\"context\"]\n",
    "        )\n",
    "    \n",
    "        model = VertexAI(model_name=model_name)\n",
    "        response = model(prompt_formatted_str)\n",
    "        prompt_df.loc[index,'response'] = response\n",
    "        \n",
    "    prompt_df.to_csv(model_response.path, index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"pandas_gbq\", \"pandas\"],\n",
    "    base_image=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-12.py310:latest\" #TODO Find Relevant Base Image!!!\n",
    ")\n",
    "def eval_dataset(\n",
    "    model_a_response: Input[Dataset],\n",
    "    model_b_response: Input[Dataset],\n",
    "    dataset_uri: str,\n",
    "    project_id:str\n",
    "    \n",
    "):\n",
    "    import pandas as pd\n",
    "    import pandas_gbq\n",
    "    input_prompt_df_a = pd.read_csv(model_a_response.path)\n",
    "    input_prompt_df_b = pd.read_csv(model_b_response.path)\n",
    "    input_prompt_df_a.rename(columns={\"response\": \"model_a_response\"}, inplace=True)\n",
    "    input_prompt_df_b.rename(columns={\"response\": \"model_b_response\"}, inplace=True)\n",
    "    eval_df = pd.merge(input_prompt_df_a,input_prompt_df_b)\n",
    "\n",
    "    pandas_gbq.to_gbq(eval_df, \n",
    "                      dataset_uri, \n",
    "                      project_id=project_id,\n",
    "                      if_exists='replace')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\", \"pandas\"],\n",
    "    base_image=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-12.py310:latest\" #TODO Find Relevant Base Image!!!\n",
    ")\n",
    "def auto_sxs_eval(\n",
    "    dataset_uri:str,\n",
    "    id_column: str,\n",
    "    inference_instruction_column: str,\n",
    "    inference_context_column: str,\n",
    "    response_a_column: str,\n",
    "    response_b_column: str,\n",
    "    bucket_uri: str,\n",
    "    project_id: str,\n",
    "    region_id:str,\n",
    "    judgements: Output[Dataset],\n",
    "    summary_metrics: Output[Dataset],\n",
    "    task: str='question_answer@latest'\n",
    "\n",
    "):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from google.cloud import aiplatform\n",
    "    \n",
    "    parameters = {\n",
    "        'evaluation_dataset': dataset_uri,\n",
    "        'id_columns': [id_column],\n",
    "        'task': task,\n",
    "        'autorater_prompt_parameters': {\n",
    "          'inference_instruction': {'column': inference_instruction_column},\n",
    "          'inference_context': {'column': inference_context_column},\n",
    "        },\n",
    "        'response_column_a': 'model_a_response',\n",
    "        'response_column_b': 'model_b_response',\n",
    "    }\n",
    "\n",
    "    aiplatform.init(project=project_id, location=region_id, staging_bucket=bucket_uri)\n",
    "\n",
    "    job = aiplatform.PipelineJob(\n",
    "        display_name='llm_eval',\n",
    "        pipeline_root=os.path.join(bucket_uri, 'llm_eval'),\n",
    "        template_path=('https://us-kfp.pkg.dev/ml-pipeline/google-cloud-registry/autosxs-template/default'),\n",
    "        parameter_values=parameters,\n",
    "    )\n",
    "    job.run()\n",
    "                                 \n",
    "    for details in job.task_details:\n",
    "        if details.task_name == \"online-evaluation-pairwise\":\n",
    "            break\n",
    "\n",
    "    # Judgments\n",
    "    judgments_uri = details.outputs[\"judgments\"].artifacts[0].uri\n",
    "    judgments_df = pd.read_json(judgments_uri, lines=True)\n",
    "    judgments_df.to_csv(judgements.path, index=False)\n",
    "    \n",
    "    for details in job.task_details:\n",
    "        if details.task_name == \"model-evaluation-text-generation-pairwise\":\n",
    "            break\n",
    "    summary_metrics_df = pd.DataFrame([details.outputs[\"autosxs_metrics\"].artifacts[0].metadata])\n",
    "    summary_metrics_df.to_csv(summary_metrics.path, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component\n",
    "def get_model_artifact(\n",
    "    model_id:str,\n",
    "    project_id:str,\n",
    "    region_id:str,\n",
    "    model_artifact: Output[Artifact]\n",
    "):\n",
    "    model_endpoint = \"https://us-central1-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION_ID}/publishers/google/models/{MODEL_ID}\".format(\n",
    "    PROJECT_ID = project_id,\n",
    "    REGION_ID = region_id,\n",
    "    MODEL_ID = model_id\n",
    "    )\n",
    "    model_artifact.path = model_endpoint\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"Given the context:\\n {context}? \\n Answer following question:\\n  {question}\"\n",
    "prompt_variables = [\"context\", \"question\"]\n",
    "prompt_file = \"gs://tadelle-372416-llmops/prompts/prompts_question_context.csv\"\n",
    "DATASET_URI = \"tadelle-372416.demo.llm_eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_bison_id = 'text-bison@002'\n",
    "gemini_bison_id = 'gemini-1.0-pro-001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"prompt_vertex_llm_apis\",\n",
    ")\n",
    "def pipeline():\n",
    "    \"\"\"A demo llm pipeline.\"\"\"\n",
    "\n",
    "    gemini_artifact = get_model_artifact(\n",
    "        model_id=gemini_bison_id,\n",
    "        project_id=PROJECT_ID,\n",
    "        region_id=REGION,\n",
    "    )\n",
    "    \n",
    "    gemini = prompt_vertex_llm_apis(\n",
    "        project_id=PROJECT_ID,\n",
    "        region_id=REGION,\n",
    "        prompt_file=prompt_file,\n",
    "        prompt_template=prompt_template,\n",
    "        prompt_variables=prompt_variables,\n",
    "        model_name=\"gemini-pro\",\n",
    "        model_endpoint = gemini_artifact.outputs[\"model_artifact\"]\n",
    "    ).set_display_name(\"gemini-pro\")\n",
    "    \n",
    "    text_bison_artifact = get_model_artifact(\n",
    "        project_id=PROJECT_ID,\n",
    "        region_id=REGION,\n",
    "        model_id=text_bison_id\n",
    "    )\n",
    "    \n",
    "    text_bison = prompt_vertex_llm_apis(\n",
    "        project_id = PROJECT_ID,\n",
    "        region_id=REGION,\n",
    "        prompt_file=prompt_file,\n",
    "        prompt_template=prompt_template,\n",
    "        prompt_variables=prompt_variables,\n",
    "        model_name=\"text-bison\",\n",
    "        model_endpoint = text_bison_artifact.outputs[\"model_artifact\"]\n",
    "    ).set_display_name(\"text-bison@002\")\n",
    "    \n",
    "    eval_llm = eval_dataset(\n",
    "        model_a_response=gemini.outputs[\"model_response\"],\n",
    "        model_b_response=text_bison.outputs[\"model_response\"],\n",
    "        dataset_uri=DATASET_URI,\n",
    "        project_id=PROJECT_ID\n",
    "    ).after(gemini, text_bison)\n",
    "        \n",
    "    auto_sxs_eval(\n",
    "        dataset_uri=DATASET_URI,\n",
    "        id_column=\"id\",\n",
    "        inference_instruction_column=\"question\",\n",
    "        inference_context_column=\"context\",\n",
    "        response_a_column=\"model_a_response\",\n",
    "        response_b_column=\"model_b_response\",        \n",
    "        project_id = PROJECT_ID,\n",
    "        region_id=REGION,\n",
    "        bucket_uri=BUCKET_URI,\n",
    "        \n",
    "    ).after(eval_llm)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"llm-pipeline.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PIPELINE_ROOT=BUCKET_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"prompt_vertex_llm_apis\",\n",
    "    template_path=\"llm-pipeline.yaml\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/81492352225/locations/us-central1/pipelineJobs/prompt-vertex-llm-apis-20240326182001\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/81492352225/locations/us-central1/pipelineJobs/prompt-vertex-llm-apis-20240326182001')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/prompt-vertex-llm-apis-20240326182001?project=81492352225\n",
      "Associating projects/81492352225/locations/us-central1/pipelineJobs/prompt-vertex-llm-apis-20240326182001 to Experiment: genai-llm\n"
     ]
    }
   ],
   "source": [
    "job.submit(\n",
    "    experiment=experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "kfp2_pipeline.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
